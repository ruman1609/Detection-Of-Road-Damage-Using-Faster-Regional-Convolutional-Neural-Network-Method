{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5309df84",
   "metadata": {},
   "source": [
    "# Data Preparation (from .xml to .tfrecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80f1a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, pandas as pd, xml.etree.ElementTree as ET, tensorflow as tf, cv2, numpy as np\n",
    "\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0e3dce8",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def read_label_map(label_map_path):\n",
    "    item_id = None\n",
    "    item_name = None\n",
    "    items = {}\n",
    "\n",
    "    with open(label_map_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            line.replace(\" \", \"\")\n",
    "            if line == \"item{\":\n",
    "                pass\n",
    "            elif line == \"}\":\n",
    "                pass\n",
    "            elif \"id\" in line:\n",
    "                item_id = int(line.split(\":\", 1)[1].strip())\n",
    "            elif \"name\" in line:\n",
    "                item_name = line.split(\":\", 1)[1].replace(\"'\", \"\").replace(\"\\\"\", \"\").strip()\n",
    "\n",
    "            if item_id is not None and item_name is not None:\n",
    "                items[item_name] = item_id\n",
    "                item_id = None\n",
    "                item_name = None\n",
    "\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a74edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_text_to_num(label_map_dict, text):\n",
    "    return label_map_dict[text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bfd534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regroup(dataframe, group = \"filename\"):\n",
    "    data = namedtuple(\"data\", [\"filename\", \"objects\"])\n",
    "    group_by = dataframe.groupby(group)\n",
    "    return [data(filename, group_by.get_group(x)) for filename, x in zip(group_by.groups.keys(), group_by.groups)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5df71ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    # If the value is an eager tensor BytesList won't unpack a string from an EagerTensor.\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() \n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3731652f-f96e-4e05-b09c-32a572b9a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a040bff5-9553-42cc-8443-df679f2c1406",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02d17726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pothole': 1, 'crack': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = \"./label_map.pbtxt\"\n",
    "label_map_dict = read_label_map(label_map)\n",
    "\n",
    "label_map_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fb27294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_csv(path, label_map):\n",
    "    xml_list = []\n",
    "    for file in glob.glob(path + \"/*.xml\"):\n",
    "        tree = ET.parse(file)\n",
    "        root = tree.getroot()\n",
    "        members = root.findall(\"object\")\n",
    "        objects_class = [member[0].text for member in members]\n",
    "        is_pothole = \"pothole\" in objects_class\n",
    "#         print(root.find(\"filename\").text)\n",
    "        for member in members:\n",
    "            if member[0].text == \"plain\": continue\n",
    "            if is_pothole:\n",
    "                if member[0].text == \"crack\": continue\n",
    "            xml_list.append((\n",
    "                root.find(\"filename\").text,\n",
    "                int(member[4][0].text),\n",
    "                int(member[4][1].text),\n",
    "                int(member[4][2].text),\n",
    "                int(member[4][3].text),\n",
    "                int(class_text_to_num(label_map, member[0].text)),\n",
    "            ))  # filename, x1, y1, x2, y2, class\n",
    "#             else: continue\n",
    "    columns = [\"filename\", \"x1\", \"y1\", \"x2\", \"y2\", \"class\"]\n",
    "    return pd.DataFrame(xml_list, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d40bbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_ex(group, path):\n",
    "    # Color\n",
    "    image = cv2.imread(os.path.join(path, group.filename), cv2.IMREAD_COLOR)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # end of Color\n",
    "    \n",
    "    # Grayscale\n",
    "#     image = cv2.imread(os.path.join(path, group.filename), cv2.IMREAD_GRAYSCALE)\n",
    "#     image = image.reshape(image.shape[0], image.shape[1], 1)\n",
    "    # end of Grayscale\n",
    "    \n",
    "    filename = group.filename.encode(\"utf-8\")\n",
    "    label = []\n",
    "    bbox = []\n",
    "    for i, data in group.objects.iterrows():\n",
    "        bbox.append([float(data[\"y1\"] / 512), float(data[\"x1\"] / 512), float(data[\"y2\"] / 512), float(data[\"x2\"] / 512)])\n",
    "        label.append(data[\"class\"])\n",
    "    bbox = np.array(bbox)\n",
    "    bbox = bbox.astype(\"float32\")\n",
    "    features = tf.train.Features(feature = {\n",
    "        \"filename\": bytes_feature(filename),\n",
    "        \"pic\": bytes_feature(tf.io.serialize_tensor(image)),\n",
    "        \"bbox\": bytes_feature(tf.io.serialize_tensor(bbox)),\n",
    "        \"label\": bytes_feature(tf.io.serialize_tensor(np.array(label))),\n",
    "    })\n",
    "    return tf.train.Example(features = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1eb17542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_record(group_x, path, writer):\n",
    "    i = 0\n",
    "    for group in group_x:\n",
    "        tf_ex = create_tf_ex(group, path)\n",
    "        writer.write(tf_ex.SerializeToString())\n",
    "        i += 1\n",
    "    writer.close()\n",
    "    print(\"DONE {}\\n{}\".format(path, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6318515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"../dataset/train/augmented\"\n",
    "path_test = \"../dataset/test/augmented\"\n",
    "\n",
    "train_out = \"./train.tfrecord\"\n",
    "test_out = \"./test.tfrecord\"\n",
    "\n",
    "writer_train = tf.io.TFRecordWriter(train_out)\n",
    "writer_test = tf.io.TFRecordWriter(test_out)\n",
    "\n",
    "df_train = xml_to_csv(path_train, label_map_dict)\n",
    "df_test = xml_to_csv(path_test, label_map_dict)\n",
    "\n",
    "group_train = regroup(df_train)\n",
    "group_test = regroup(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d60f4d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE ../dataset/train/augmented\n",
      "1950\n",
      "DONE ../dataset/test/augmented\n",
      "480\n"
     ]
    }
   ],
   "source": [
    "create_tf_record(group_train, path_train, writer_train)\n",
    "create_tf_record(group_test, path_test, writer_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2ed8ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183aff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_roi_tf_ex(group, path, label_map):\n",
    "    # Color\n",
    "    image = cv2.imread(os.path.join(path, group.filename), cv2.IMREAD_COLOR)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # end of Color\n",
    "\n",
    "    # Grayscale\n",
    "    # image = cv2.imread(os.path.join(path, group.filename), cv2.IMREAD_GRAYSCALE)\n",
    "    # image = image.reshape(image.shape[0], image.shape[1], 1)\n",
    "    # end of Grayscale\n",
    "\n",
    "    # image = open(os.path.join(path, group.filename), \"rb\").read()\n",
    "\n",
    "    label = -1\n",
    "    filename = group.filename.encode(\"utf-8\")\n",
    "    for i, data in group.objects.iterrows():\n",
    "        label = class_text_to_num(label_map, data[\"class\"]) - 1\n",
    "\n",
    "    features = tf.train.Features(feature = {\n",
    "        \"filename\": bytes_feature(filename),\n",
    "        \"image\": bytes_feature(tf.io.serialize_tensor(image)),\n",
    "        \"label\": int64_feature(label),\n",
    "    })\n",
    "    return tf.train.Example(features = features).SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320a8d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_record_roi(group_x, path, label_map_roi, writer):\n",
    "    total = 0\n",
    "    for group in group_x:\n",
    "        writer.write(create_roi_tf_ex(group, path, label_map_roi))\n",
    "        total += 1\n",
    "    writer.close()\n",
    "    print(\"DONE {}\\n{}\".format(path, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d0a5b1-2fd4-4b20-a806-cadd43ae20aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map_roi_path = \"./label_map.pbtxt\"\n",
    "label_map_roi = read_label_map(label_map_roi_path)\n",
    "print(label_map_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b008ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_out_roi = \"./train_roi.tfrecord\"\n",
    "test_out_roi = \"./test_roi.tfrecord\"\n",
    "\n",
    "train_writer = tf.io.TFRecordWriter(train_out_roi)\n",
    "test_writer = tf.io.TFRecordWriter(test_out_roi)\n",
    "\n",
    "train_roi_path = \"../dataset/train_roi/ready\"\n",
    "test_roi_path = \"../dataset/test_roi/ready\"\n",
    "\n",
    "train_df = pd.read_csv(train_roi_path + \"/train.csv\", encoding='utf-8')\n",
    "test_df = pd.read_csv(test_roi_path + \"/test.csv\", encoding='utf-8')\n",
    "\n",
    "train_group = regroup(train_df)\n",
    "test_group = regroup(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f9db7c-d9ba-4b10-afc2-d264bee40d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tf_record_roi(train_group, train_roi_path, label_map_roi, train_writer)\n",
    "create_tf_record_roi(test_group, test_roi_path, label_map_roi, test_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9909e0-d4cd-4966-bd87-f03db4f5a3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
