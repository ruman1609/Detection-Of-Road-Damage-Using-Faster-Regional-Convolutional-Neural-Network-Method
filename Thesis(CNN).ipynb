{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94ac360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf, matplotlib.pyplot as plt, os, numpy as np, matplotlib.pyplot as plt, matplotlib.patches as patches\n",
    "from sklearn.metrics import confusion_matrix as C_M, accuracy_score as A_S, classification_report as C_R\n",
    "from framework.utils import bbox_utils, data_utils, drawing_utils, eval_utils, io_utils, train_utils\n",
    "from framework.models import rpn_vgg16, faster_rcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741bc394",
   "metadata": {},
   "source": [
    "# Read Dataset from TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "574c7d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "IMAGE_SIZE = 512  # make sure had same size with the picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c857b99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(img):\n",
    "    img = tf.cast(img, tf.int32)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a76049aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord(example):\n",
    "    tfrecord_format = {\n",
    "        \"filename\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"pic\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"bbox\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
    "    filename = tf.cast(example[\"filename\"], tf.string)\n",
    "    image = decode_image(tf.io.parse_tensor(example[\"pic\"], out_type = tf.uint8))\n",
    "    bbox = tf.io.parse_tensor(example[\"bbox\"], out_type = tf.float32)\n",
    "    label = tf.io.parse_tensor(example[\"label\"], out_type = tf.int32)\n",
    "    return {\"filename\": filename, \"image\": image, \"bbox\": bbox, \"label\": label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7dc4e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filenames):\n",
    "    ignore_order = tf.data.Options()\n",
    "    ignore_order.experimental_deterministic = False  # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(filenames)  # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order)  # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(read_tfrecord)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55a6b241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(filenames):\n",
    "    dataset = load_dataset(filenames)\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fc132b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_label_map(label_map_path):\n",
    "    item_id = None\n",
    "    item_name = None\n",
    "    items = {}\n",
    "\n",
    "    with open(label_map_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            line.replace(\" \", \"\")\n",
    "            if line == \"item{\":\n",
    "                pass\n",
    "            elif line == \"}\":\n",
    "                pass\n",
    "            elif \"id\" in line:\n",
    "                item_id = int(line.split(\":\", 1)[1].strip())\n",
    "            elif \"name\" in line:\n",
    "                item_name = line.split(\":\", 1)[1].replace(\"'\", \"\").replace(\"\\\"\", \"\").strip()\n",
    "\n",
    "            if item_id is not None and item_name is not None:\n",
    "                items[item_name] = item_id\n",
    "                item_id = None\n",
    "                item_name = None\n",
    "\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8135524",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map_path = \"./data_preparation/label_map.pbtxt\"\n",
    "label_map_dict = read_label_map(label_map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17ca36eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_text(result, doc = label_map_dict):\n",
    "    for key, value in doc.items():\n",
    "        if(value == result + 1):\n",
    "            return key\n",
    "    return \"Unpredictable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40c679cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: {filename: (), image: <unknown>, bbox: <unknown>, label: <unknown>}, types: {filename: tf.string, image: tf.int32, bbox: tf.float32, label: tf.int32}>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = get_dataset(\"./data_preparation/train.tfrecord\")\n",
    "\n",
    "test_data = get_dataset(\"./data_preparation/test.tfrecord\")\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18140a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(data, n):\n",
    "    print(data)\n",
    "    for dat in data.take(n):\n",
    "        plt.imshow(dat[\"image\"])\n",
    "        for coord in dat[\"bbox\"]: # bbox is ymin, xmin, ymax, xmax\n",
    "            coord *= IMAGE_SIZE\n",
    "            rect = patches.Rectangle(\n",
    "                (coord[1].numpy(), coord[0].numpy()),  # x1, y1\n",
    "                coord[3].numpy() - coord[1].numpy(),  # width\n",
    "                coord[2].numpy() - coord[0].numpy(),  # height\n",
    "                linewidth = 2, edgecolor = \"r\", fill = False)\n",
    "            plt.gca().add_patch(rect)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4c6670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_data(train_data, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d963e4",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6916477",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "epochs = 50\n",
    "load_weights = False\n",
    "backbone = \"vgg16\"\n",
    "\n",
    "hyper_params = train_utils.get_hyper_params(backbone)\n",
    "train_total_item = len(list(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29f3627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(label_map_dict.keys())\n",
    "# We add 1 class for background\n",
    "hyper_params[\"total_labels\"] = len(labels) + 1\n",
    "train_data = train_data.map(lambda data : data_utils.preprocessing_before_frcnn(data, IMAGE_SIZE, IMAGE_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75ad2ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shapes = data_utils.get_data_shapes()\n",
    "padding_values = data_utils.get_padding_values()\n",
    "train_data = train_data.padded_batch(batch_size, padded_shapes=data_shapes, padding_values=padding_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d25c0b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = bbox_utils.generate_anchors(hyper_params)\n",
    "frcnn_train_feed = train_utils.faster_rcnn_generator(train_data, anchors, hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7487d397",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpn_model, feature_extractor = rpn_vgg16.get_model_vgg16(hyper_params)\n",
    "frcnn_model = faster_rcnn.get_model_frcnn(feature_extractor, rpn_model, anchors, hyper_params)\n",
    "frcnn_model.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-5),\n",
    "                    loss=[None] * len(frcnn_model.output))\n",
    "faster_rcnn.init_model_frcnn(frcnn_model, hyper_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
